{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "Los arboles de decision tienen muchas ventajas, destacando destacando su habilidad de funcionar con variables continuas o categoricas sin mucha preparacion requerida, su interpretabilidad, y su capacidad de percibir y modelar relaciones no lineales en los datos. Sin embargo, su capacidad predictiva no es muy buena, cayendo facilmente victicas de *overfitting* al crecer arboles muy profundos. Ademas, los arboles sueles ser muy inestables a cambios sutiles en los datos---cambiar solo un par de observaciones puede tener cambios drasticos en la forma que tomara el arbol de decision.\n",
    "\n",
    "Esta inestabilidad es aprovechada por los *ensemble methods*---modelos que combinan multiples arboles de decision en un estimador final que supera drasticamente el desempeño de un arbol individual. Las dos familias princiaples de estos modelos son:\n",
    "- *Averaging methods*: varios estimadores son combinados de manera simple, promediando el valor (o probabilidad en el caso de clasificacion) o por un sistema de votacion.\n",
    "- *Boosting methods*: Los estimadores son agregados de manera secuencial, cada uno buscando mejorar marginalmente el desempeño del anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "*Random Forests* se refiere a una metodologia de *averaging* ensemble que introduce aleatoriedad a la construccion de cada arbol en el \"bosque\", una tecnica conocida como *perturb-and-combine*, que aprovecha la inestabilidad inehernte en los arboles de decision para terminar con un conjunto de arboles muy distintos entre si, cada uno capturando una relacion levemente distinta.\n",
    "\n",
    "La aleatoriedad es introducida de dos formas:\n",
    "- *bagging*: Cada arbol se construye con una sub-muestra de todos los datos disponibles, de manera que dos arboles distintos ven distintas observaciones y por lo tanto resultan con estructuras distintas (e idealmente complementarias).\n",
    "- Sub-conjunto de atributos: Ademas de restringir el numero de observaciones, cada nodo del arbol realiza el *split* tomando en consideracion un sub-conjunto de todos los atributos (variables explicativas) disponibles.\n",
    "\n",
    "El resultado es un estimador que posiblemente tiene un poco mas de sesgo, relativo a un estimador que consiste en un solo arbol sin elementos de aleatoriedad, pero usualmente la varianza del estimador agregado cae de manera que mas que compensa este sesgo, resultando en un mejor estimador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacion con Scikit-Learn\n",
    "*Scikit-learn* incluye este estimador para clasificacion y regresion. Los hiper-parametros disponibles consisten en los inherentes a los arboles de decision, y ademas algunos adicionales que regulan el *ensemble*:\n",
    "- `n_estimators`: El numero de arboles a estimar. Mientras mas mejor (aunque con rendimiento decreciente), pero a costo de tiempo en entrenar.\n",
    "- `max_features`: Numero maximo de atributos a considerar al realizar cada split. Un numero mas bajo resultara en una mayor reduccion en la varianza del estimador final, a costo de un mayor sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_features='auto',\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             oob_score=True\n",
    "                            )\n",
    "\n",
    "class_weights = {0: 5, 1: 1, 2: 1}\n",
    "sample_weights = compute_sample_weight(class_weight=class_weights, y=iris.target)\n",
    "\n",
    "print(sample_weights)\n",
    "clf.fit(iris.data, iris.target, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [6, 3], [7, 1], [9, 1], [9, 5], [0, 4]] [0, 0, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\Envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos falsos\n",
    "n_samples = 6\n",
    "X = [[np.random.randint(0, 10), np.random.randint(0, 10)]\n",
    "     for _ in range(n_samples)]\n",
    "y = [0, 0, 0, 1, 0, 1]\n",
    "print(X, y)\n",
    "# Instanciar clasificador con argumentos default\n",
    "clf = RandomForestClassifier()\n",
    "# lista de pesos a usar\n",
    "weights = [1, 1, 1, 2, 1, 2]\n",
    "# Confirmar que tienen el mismo tamaño\n",
    "assert len(weights) == len(y)\n",
    "# Entrenar, pasando los pesos especificados\n",
    "clf.fit(X, y, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "weights = {0: 5, 1: 1, 2: 1}\n",
    "compute_sample_weight(class_weight=weights, y=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
